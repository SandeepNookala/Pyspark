{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o-mw36UNw7Mk",
        "ZQjxA0eCPP1M",
        "CY9hfUTvBayi",
        "qEM7RKgLRkwK",
        "BZqeKUparYFJ",
        "Ht8gh-rAzljT",
        "l3Qj_hkgOCqD",
        "PdpL7EnhgKUY",
        "92kZBlp6OqSi",
        "F7fr2-iDO_AS",
        "q66gjenfWVif",
        "4LCR2ou1j6ej",
        "YAmzJhkhz2T8",
        "Kagev9gFLmde",
        "uJDO9Mk1HT_5",
        "qjm5YnWn1E5C",
        "Q3Pdmj4p1Zyn",
        "nJxbbzLg182I"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SparkSession"
      ],
      "metadata": {
        "id": "o-mw36UNw7Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local').appName('demo').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "OHNW-wKVqbxd",
        "outputId": "7fe7aaa0-c600-416d-e4e5-bd70bc0ab155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=389290149e608ff9517eecd695b328418dbebf0b6047eb3552febadca5b306a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f298026fc70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2f3c75a46e2e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import Functions and types"
      ],
      "metadata": {
        "id": "ZQjxA0eCPP1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "DJrjlvMMPPCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read without header"
      ],
      "metadata": {
        "id": "CY9hfUTvBayi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = spark.read.format('csv').load('/content/address.txt')\n",
        "file.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eDGO69aJYHa",
        "outputId": "306e7bb3-834b-4dad-9f9e-96b4239c413a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|_c0                      |\n",
            "+-------------------------+\n",
            "|Hyderabad-Telengana---123|\n",
            "|Bangalore-Karnataka---245|\n",
            "+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split and dropping columns"
      ],
      "metadata": {
        "id": "qEM7RKgLRkwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = file.withColumn('split',split('_c0','-'))\n",
        "\n",
        "df2 = df1.withColumn('city', col('split')[0]).withColumn('state',col('split')[1]).withColumn('Id',col('split')[4]).drop('_c0','split')\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px4AfyrLRtzT",
        "outputId": "3f55bcf8-aa80-4bfa-cddc-96af69f0acde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---+\n",
            "|     city|    state| Id|\n",
            "+---------+---------+---+\n",
            "|Hyderabad|Telengana|123|\n",
            "|Bangalore|Karnataka|245|\n",
            "+---------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reading csv file"
      ],
      "metadata": {
        "id": "BZqeKUparYFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format('csv').option('header',True).option('inferSchema',True).option('nullValue','null').load('/content/employee.csv')\n",
        "df.show(5)\n",
        "df.printSchema()\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LKBkAIbq0W6",
        "outputId": "e9c38cb2-7f71-474a-bf13-bc27f79bac96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+--------+----+----------+----+----+------+------------+\n",
            "|EMPNO| ENAME|     JOB| MGR|  HIREDATE| SAL|COMM|DEPTNO|UPDATED_DATE|\n",
            "+-----+------+--------+----+----------+----+----+------+------------+\n",
            "| 7369| SMITH|   CLERK|7902|17-12-1980| 800|null|    20|  01-01-2022|\n",
            "| 7499| ALLEN|SALESMAN|7698|20-02-1981|1600| 300|    30|  02-01-2022|\n",
            "| 7521|  WARD|SALESMAN|7698|22-02-1981|1250| 500|    30|  03-01-2022|\n",
            "| 7566| JONES| MANAGER|7839|04-02-1981|2975|null|    20|  04-01-2022|\n",
            "| 7654|MARTIN|SALESMAN|7698|21-09-1981|1250| 600|    30|  05-01-2022|\n",
            "+-----+------+--------+----+----------+----+----+------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- EMPNO: integer (nullable = true)\n",
            " |-- ENAME: string (nullable = true)\n",
            " |-- JOB: string (nullable = true)\n",
            " |-- MGR: integer (nullable = true)\n",
            " |-- HIREDATE: string (nullable = true)\n",
            " |-- SAL: integer (nullable = true)\n",
            " |-- COMM: integer (nullable = true)\n",
            " |-- DEPTNO: integer (nullable = true)\n",
            " |-- UPDATED_DATE: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing schema for dataFrame"
      ],
      "metadata": {
        "id": "Ht8gh-rAzljT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType([StructField(\"EMPNO\", IntegerType(), True),\\\n",
        "                     StructField(\"ENAME\", StringType(), True),\\\n",
        "                     StructField(\"JOB\", StringType(), True),\\\n",
        "                     StructField(\"MGR\", IntegerType(), True),\\\n",
        "                     StructField(\"HIREDATE\", DateType(), True),\\\n",
        "                     StructField(\"SAL\", IntegerType(), True),\\\n",
        "                     StructField(\"COMM\", IntegerType(), True),\\\n",
        "                     StructField(\"DEPTNO\", IntegerType(), True),\\\n",
        "                     StructField(\"UPDATED_DATE\",DateType(), True)\\\n",
        "])"
      ],
      "metadata": {
        "id": "5WYqp_jOznnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#how to handle yy date format in pyspark for before 2000 data"
      ],
      "metadata": {
        "id": "l3Qj_hkgOCqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yy_df = spark.read.format('csv').option('header',True).option('sep','|').option('inferSchema',True).option('nullValue','null').load('/content/emp_pipe_yy.txt')\n",
        "\n",
        "yy_df.show()\n",
        "yy_df.printSchema()"
      ],
      "metadata": {
        "id": "4AM85_FOOHG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Spark defaulty chooses year after 2000\n",
        "\n",
        "# we need to set spark sql legcy timeparserpolicy to legacy -- Useful for less columns data only ,if more data means need ask source system set proper date format\n",
        "\n",
        "spark.conf.set('spark.sql.legacy.timeParserPolicy','LEGACY')\n",
        "\n",
        "yy_df.withColumn('DATE',to_date('UPDATED_DATE','dd-mm-yy')).show()"
      ],
      "metadata": {
        "id": "M-2XqadYOKlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#how to get number of null in all columns"
      ],
      "metadata": {
        "id": "PdpL7EnhgKUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_csv.select([count(when(col(i).isNull(),i)).alias(i) for i in df_csv.columns]).show()"
      ],
      "metadata": {
        "id": "WNERrK4GgLA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word count program step by step"
      ],
      "metadata": {
        "id": "92kZBlp6OqSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd = spark.sparkContext.textFile(\"/content/word.txt\")\n",
        "\n",
        "print(type(rd))\n",
        "print(rd.collect())       # no.of lines\n",
        "print(rd.count())"
      ],
      "metadata": {
        "id": "oGubXKetOvSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd1 = rd.map(lambda x : x.encode('utf-8'))\n",
        "\n",
        "print(rd1.collect())"
      ],
      "metadata": {
        "id": "oInXqs9xOw9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map - gives Number of lists of strings\n",
        "\n",
        "rd2 = rd.map(lambda x:x.split(' '))\n",
        "print(type(rd2))\n",
        "print(rd2.collect())"
      ],
      "metadata": {
        "id": "CQBnIbjrOyog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flatmap - gives single list of strings\n",
        "\n",
        "rd3 = rd.flatMap(lambda x : x.split(' '))\n",
        "print(rd3.collect())"
      ],
      "metadata": {
        "id": "bB-yrUZbO1GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assiging value to strings\n",
        "rd4 =  rd3.map(lambda x : (x,1))\n",
        "print(rd4.collect())"
      ],
      "metadata": {
        "id": "-SKuTPj_O1r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduceByKey -  groupping and aggregating same keys from rd4\n",
        "\n",
        "rd5 = rd4.reduceByKey(lambda x ,y : x+y)\n",
        "\n",
        "print(rd5.collect())"
      ],
      "metadata": {
        "id": "nHRyzBLpO3dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word count in single line - Find No.of Occurences of single word"
      ],
      "metadata": {
        "id": "F7fr2-iDO_AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RDD = spark.sparkContext.textFile('/content/word.txt').flatMap(lambda x : x.split(' ')).map(lambda x:(x,1)).reduceByKey(lambda x,y : x+y)\n",
        "\n",
        "RDD.collect()"
      ],
      "metadata": {
        "id": "WWgc9NJ7PA9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Skip first few rows? ( Step By Step detailed)\n",
        "\n"
      ],
      "metadata": {
        "id": "q66gjenfWVif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rdd = spark.sparkContext.textFile('/content/emp_pipe_skip.txt').zipWithIndex()\n",
        "\n",
        "Rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLx1BqxERLOr",
        "outputId": "77afc40e-5f02-4014-84b5-c7551d845f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('line 1', 0),\n",
              " ('line 2', 1),\n",
              " ('line 3', 2),\n",
              " ('EMPNO|ENAME|JOB|MGR|HIREDATE|SAL|COMM|DEPTNO|UPDATED_DATE', 3),\n",
              " ('7369|SMITH|CLERK|7902|17-12-1980|800|null|20|01-01-2022', 4),\n",
              " ('7499|ALLEN|SALESMAN|7698|20-02-1981|1600|300|30|02-01-2022', 5),\n",
              " ('7521|WARD|SALESMAN|7698|22-02-1981|1250|500|30|03-01-2022', 6),\n",
              " ('7566|JONES|MANAGER|7839|04-02-1981|2975|null|20|04-01-2022', 7),\n",
              " ('7654|MARTIN|SALESMAN|7698|21-09-1981|1250|1400|30|05-01-2022', 8),\n",
              " ('7698|SGR|MANAGER|7839|05-01-1981|2850|null|30|06-01-2022', 9),\n",
              " ('7782|RAVI|MANAGER|7839|06-09-1981|2450|null|10|07-01-2022', 10),\n",
              " ('7788|SCOTT|ANALYST|7566|19-04-1987|3000|null|20|08-01-2022', 11),\n",
              " ('7839|KING|PRESIDENT|null|null|5000|null|10|null', 12),\n",
              " ('7844|TURNER|SALESMAN|7698|09-08-1981|1500|0|30|01-02-2022', 13),\n",
              " ('7876|ADAMS|CLERK|7788|23-05-1987|1100|null|20|02-02-2022', 14),\n",
              " ('7900|JAMES|CLERK|7698|12-03-1981|950|null|30|03-02-2022', 15),\n",
              " ('7902|FORD|ANALYST|7566|12-03-1981|3000|null|20|04-02-2022', 16),\n",
              " ('7934|MILLER|CLERK|7782|01-03-1982|1300|null|10|05-02-2022', 17),\n",
              " ('1234|SEKHAR|doctor|7777|null|667|78|80|06-02-2022', 18),\n",
              " ('7369|SMITH|CLERK|7902|17-12-1980|800|null|20|07-02-2022', 19),\n",
              " ('7499|ALLEN|SALESMAN|7698|20-02-1981|1600|300|30|08-02-2022', 20),\n",
              " ('7521|WARD|SALESMAN|7698|22-02-1981|1250|500|30|null', 21),\n",
              " ('7566|JONES|MANAGER|7839|04-02-1981|2975|null|20|01-02-2021', 22)]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rdd1 = Rdd.filter(lambda a : a[1]>2)\n",
        "Rdd1.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEtYpQotRjCx",
        "outputId": "c8f2db2e-2e08-412a-9823-9d1ef8cebf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('EMPNO|ENAME|JOB|MGR|HIREDATE|SAL|COMM|DEPTNO|UPDATED_DATE', 3),\n",
              " ('7369|SMITH|CLERK|7902|17-12-1980|800|null|20|01-01-2022', 4),\n",
              " ('7499|ALLEN|SALESMAN|7698|20-02-1981|1600|300|30|02-01-2022', 5),\n",
              " ('7521|WARD|SALESMAN|7698|22-02-1981|1250|500|30|03-01-2022', 6),\n",
              " ('7566|JONES|MANAGER|7839|04-02-1981|2975|null|20|04-01-2022', 7),\n",
              " ('7654|MARTIN|SALESMAN|7698|21-09-1981|1250|1400|30|05-01-2022', 8),\n",
              " ('7698|SGR|MANAGER|7839|05-01-1981|2850|null|30|06-01-2022', 9),\n",
              " ('7782|RAVI|MANAGER|7839|06-09-1981|2450|null|10|07-01-2022', 10),\n",
              " ('7788|SCOTT|ANALYST|7566|19-04-1987|3000|null|20|08-01-2022', 11),\n",
              " ('7839|KING|PRESIDENT|null|null|5000|null|10|null', 12),\n",
              " ('7844|TURNER|SALESMAN|7698|09-08-1981|1500|0|30|01-02-2022', 13),\n",
              " ('7876|ADAMS|CLERK|7788|23-05-1987|1100|null|20|02-02-2022', 14),\n",
              " ('7900|JAMES|CLERK|7698|12-03-1981|950|null|30|03-02-2022', 15),\n",
              " ('7902|FORD|ANALYST|7566|12-03-1981|3000|null|20|04-02-2022', 16),\n",
              " ('7934|MILLER|CLERK|7782|01-03-1982|1300|null|10|05-02-2022', 17),\n",
              " ('1234|SEKHAR|doctor|7777|null|667|78|80|06-02-2022', 18),\n",
              " ('7369|SMITH|CLERK|7902|17-12-1980|800|null|20|07-02-2022', 19),\n",
              " ('7499|ALLEN|SALESMAN|7698|20-02-1981|1600|300|30|08-02-2022', 20),\n",
              " ('7521|WARD|SALESMAN|7698|22-02-1981|1250|500|30|null', 21),\n",
              " ('7566|JONES|MANAGER|7839|04-02-1981|2975|null|20|01-02-2021', 22)]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing index and split using sep\n",
        "\n",
        "Rdd2 = Rdd1.map(lambda a : a[0].split('|'))\n",
        "\n",
        "Rdd2.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cD93wmZSIpl",
        "outputId": "c48a02fe-b31f-4dd7-94da-d413c9b4f3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['EMPNO',\n",
              "  'ENAME',\n",
              "  'JOB',\n",
              "  'MGR',\n",
              "  'HIREDATE',\n",
              "  'SAL',\n",
              "  'COMM',\n",
              "  'DEPTNO',\n",
              "  'UPDATED_DATE'],\n",
              " ['7369',\n",
              "  'SMITH',\n",
              "  'CLERK',\n",
              "  '7902',\n",
              "  '17-12-1980',\n",
              "  '800',\n",
              "  'null',\n",
              "  '20',\n",
              "  '01-01-2022'],\n",
              " ['7499',\n",
              "  'ALLEN',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '20-02-1981',\n",
              "  '1600',\n",
              "  '300',\n",
              "  '30',\n",
              "  '02-01-2022'],\n",
              " ['7521',\n",
              "  'WARD',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '22-02-1981',\n",
              "  '1250',\n",
              "  '500',\n",
              "  '30',\n",
              "  '03-01-2022'],\n",
              " ['7566',\n",
              "  'JONES',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '04-02-1981',\n",
              "  '2975',\n",
              "  'null',\n",
              "  '20',\n",
              "  '04-01-2022'],\n",
              " ['7654',\n",
              "  'MARTIN',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '21-09-1981',\n",
              "  '1250',\n",
              "  '1400',\n",
              "  '30',\n",
              "  '05-01-2022'],\n",
              " ['7698',\n",
              "  'SGR',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '05-01-1981',\n",
              "  '2850',\n",
              "  'null',\n",
              "  '30',\n",
              "  '06-01-2022'],\n",
              " ['7782',\n",
              "  'RAVI',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '06-09-1981',\n",
              "  '2450',\n",
              "  'null',\n",
              "  '10',\n",
              "  '07-01-2022'],\n",
              " ['7788',\n",
              "  'SCOTT',\n",
              "  'ANALYST',\n",
              "  '7566',\n",
              "  '19-04-1987',\n",
              "  '3000',\n",
              "  'null',\n",
              "  '20',\n",
              "  '08-01-2022'],\n",
              " ['7839', 'KING', 'PRESIDENT', 'null', 'null', '5000', 'null', '10', 'null'],\n",
              " ['7844',\n",
              "  'TURNER',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '09-08-1981',\n",
              "  '1500',\n",
              "  '0',\n",
              "  '30',\n",
              "  '01-02-2022'],\n",
              " ['7876',\n",
              "  'ADAMS',\n",
              "  'CLERK',\n",
              "  '7788',\n",
              "  '23-05-1987',\n",
              "  '1100',\n",
              "  'null',\n",
              "  '20',\n",
              "  '02-02-2022'],\n",
              " ['7900',\n",
              "  'JAMES',\n",
              "  'CLERK',\n",
              "  '7698',\n",
              "  '12-03-1981',\n",
              "  '950',\n",
              "  'null',\n",
              "  '30',\n",
              "  '03-02-2022'],\n",
              " ['7902',\n",
              "  'FORD',\n",
              "  'ANALYST',\n",
              "  '7566',\n",
              "  '12-03-1981',\n",
              "  '3000',\n",
              "  'null',\n",
              "  '20',\n",
              "  '04-02-2022'],\n",
              " ['7934',\n",
              "  'MILLER',\n",
              "  'CLERK',\n",
              "  '7782',\n",
              "  '01-03-1982',\n",
              "  '1300',\n",
              "  'null',\n",
              "  '10',\n",
              "  '05-02-2022'],\n",
              " ['1234', 'SEKHAR', 'doctor', '7777', 'null', '667', '78', '80', '06-02-2022'],\n",
              " ['7369',\n",
              "  'SMITH',\n",
              "  'CLERK',\n",
              "  '7902',\n",
              "  '17-12-1980',\n",
              "  '800',\n",
              "  'null',\n",
              "  '20',\n",
              "  '07-02-2022'],\n",
              " ['7499',\n",
              "  'ALLEN',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '20-02-1981',\n",
              "  '1600',\n",
              "  '300',\n",
              "  '30',\n",
              "  '08-02-2022'],\n",
              " ['7521',\n",
              "  'WARD',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '22-02-1981',\n",
              "  '1250',\n",
              "  '500',\n",
              "  '30',\n",
              "  'null'],\n",
              " ['7566',\n",
              "  'JONES',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '04-02-1981',\n",
              "  '2975',\n",
              "  'null',\n",
              "  '20',\n",
              "  '01-02-2021']]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collect columns headers\n",
        "columns = Rdd2.collect()[0]\n",
        "\n",
        "print(columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mchUAClPSIoK",
        "outputId": "9b88825b-bec9-4ac4-ea90-e914b71e7301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EMPNO', 'ENAME', 'JOB', 'MGR', 'HIREDATE', 'SAL', 'COMM', 'DEPTNO', 'UPDATED_DATE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# skip first row\n",
        "kipline = Rdd2.first()\n",
        "\n",
        "print(skipline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tri-XjAvVAXk",
        "outputId": "6298b540-fc0c-416d-dcdf-6f3ba15dac2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EMPNO', 'ENAME', 'JOB', 'MGR', 'HIREDATE', 'SAL', 'COMM', 'DEPTNO', 'UPDATED_DATE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making df from rdd\n",
        "\n",
        "DF = Rdd2.filter(lambda a : a != skipline).toDF(columns)\n",
        "\n",
        "DF.show()\n",
        "\n",
        "DF.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTCVUBCGVeIa",
        "outputId": "95bec92e-d7b1-4354-cf37-95e3bbd0e9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+----+----------+----+----+------+------------+\n",
            "|EMPNO| ENAME|      JOB| MGR|  HIREDATE| SAL|COMM|DEPTNO|UPDATED_DATE|\n",
            "+-----+------+---------+----+----------+----+----+------+------------+\n",
            "| 7369| SMITH|    CLERK|7902|17-12-1980| 800|null|    20|  01-01-2022|\n",
            "| 7499| ALLEN| SALESMAN|7698|20-02-1981|1600| 300|    30|  02-01-2022|\n",
            "| 7521|  WARD| SALESMAN|7698|22-02-1981|1250| 500|    30|  03-01-2022|\n",
            "| 7566| JONES|  MANAGER|7839|04-02-1981|2975|null|    20|  04-01-2022|\n",
            "| 7654|MARTIN| SALESMAN|7698|21-09-1981|1250|1400|    30|  05-01-2022|\n",
            "| 7698|   SGR|  MANAGER|7839|05-01-1981|2850|null|    30|  06-01-2022|\n",
            "| 7782|  RAVI|  MANAGER|7839|06-09-1981|2450|null|    10|  07-01-2022|\n",
            "| 7788| SCOTT|  ANALYST|7566|19-04-1987|3000|null|    20|  08-01-2022|\n",
            "| 7839|  KING|PRESIDENT|null|      null|5000|null|    10|        null|\n",
            "| 7844|TURNER| SALESMAN|7698|09-08-1981|1500|   0|    30|  01-02-2022|\n",
            "| 7876| ADAMS|    CLERK|7788|23-05-1987|1100|null|    20|  02-02-2022|\n",
            "| 7900| JAMES|    CLERK|7698|12-03-1981| 950|null|    30|  03-02-2022|\n",
            "| 7902|  FORD|  ANALYST|7566|12-03-1981|3000|null|    20|  04-02-2022|\n",
            "| 7934|MILLER|    CLERK|7782|01-03-1982|1300|null|    10|  05-02-2022|\n",
            "| 1234|SEKHAR|   doctor|7777|      null| 667|  78|    80|  06-02-2022|\n",
            "| 7369| SMITH|    CLERK|7902|17-12-1980| 800|null|    20|  07-02-2022|\n",
            "| 7499| ALLEN| SALESMAN|7698|20-02-1981|1600| 300|    30|  08-02-2022|\n",
            "| 7521|  WARD| SALESMAN|7698|22-02-1981|1250| 500|    30|        null|\n",
            "| 7566| JONES|  MANAGER|7839|04-02-1981|2975|null|    20|  01-02-2021|\n",
            "+-----+------+---------+----+----------+----+----+------+------------+\n",
            "\n",
            "root\n",
            " |-- EMPNO: string (nullable = true)\n",
            " |-- ENAME: string (nullable = true)\n",
            " |-- JOB: string (nullable = true)\n",
            " |-- MGR: string (nullable = true)\n",
            " |-- HIREDATE: string (nullable = true)\n",
            " |-- SAL: string (nullable = true)\n",
            " |-- COMM: string (nullable = true)\n",
            " |-- DEPTNO: string (nullable = true)\n",
            " |-- UPDATED_DATE: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skip rows in given file ?"
      ],
      "metadata": {
        "id": "4LCR2ou1j6ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = spark.sparkContext.textFile('/content/emp_pipe_skip.txt').zipWithIndex().filter(lambda a : a[1]>2).map(lambda a : a[0].split('|'))\n",
        "\n",
        "r1.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkV0T1mZWdVq",
        "outputId": "a078acf9-14c4-4b35-acba-a2cde8ec69f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['EMPNO',\n",
              "  'ENAME',\n",
              "  'JOB',\n",
              "  'MGR',\n",
              "  'HIREDATE',\n",
              "  'SAL',\n",
              "  'COMM',\n",
              "  'DEPTNO',\n",
              "  'UPDATED_DATE'],\n",
              " ['7369',\n",
              "  'SMITH',\n",
              "  'CLERK',\n",
              "  '7902',\n",
              "  '17-12-1980',\n",
              "  '800',\n",
              "  'null',\n",
              "  '20',\n",
              "  '01-01-2022'],\n",
              " ['7499',\n",
              "  'ALLEN',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '20-02-1981',\n",
              "  '1600',\n",
              "  '300',\n",
              "  '30',\n",
              "  '02-01-2022'],\n",
              " ['7521',\n",
              "  'WARD',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '22-02-1981',\n",
              "  '1250',\n",
              "  '500',\n",
              "  '30',\n",
              "  '03-01-2022'],\n",
              " ['7566',\n",
              "  'JONES',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '04-02-1981',\n",
              "  '2975',\n",
              "  'null',\n",
              "  '20',\n",
              "  '04-01-2022'],\n",
              " ['7654',\n",
              "  'MARTIN',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '21-09-1981',\n",
              "  '1250',\n",
              "  '1400',\n",
              "  '30',\n",
              "  '05-01-2022'],\n",
              " ['7698',\n",
              "  'SGR',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '05-01-1981',\n",
              "  '2850',\n",
              "  'null',\n",
              "  '30',\n",
              "  '06-01-2022'],\n",
              " ['7782',\n",
              "  'RAVI',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '06-09-1981',\n",
              "  '2450',\n",
              "  'null',\n",
              "  '10',\n",
              "  '07-01-2022'],\n",
              " ['7788',\n",
              "  'SCOTT',\n",
              "  'ANALYST',\n",
              "  '7566',\n",
              "  '19-04-1987',\n",
              "  '3000',\n",
              "  'null',\n",
              "  '20',\n",
              "  '08-01-2022'],\n",
              " ['7839', 'KING', 'PRESIDENT', 'null', 'null', '5000', 'null', '10', 'null'],\n",
              " ['7844',\n",
              "  'TURNER',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '09-08-1981',\n",
              "  '1500',\n",
              "  '0',\n",
              "  '30',\n",
              "  '01-02-2022'],\n",
              " ['7876',\n",
              "  'ADAMS',\n",
              "  'CLERK',\n",
              "  '7788',\n",
              "  '23-05-1987',\n",
              "  '1100',\n",
              "  'null',\n",
              "  '20',\n",
              "  '02-02-2022'],\n",
              " ['7900',\n",
              "  'JAMES',\n",
              "  'CLERK',\n",
              "  '7698',\n",
              "  '12-03-1981',\n",
              "  '950',\n",
              "  'null',\n",
              "  '30',\n",
              "  '03-02-2022'],\n",
              " ['7902',\n",
              "  'FORD',\n",
              "  'ANALYST',\n",
              "  '7566',\n",
              "  '12-03-1981',\n",
              "  '3000',\n",
              "  'null',\n",
              "  '20',\n",
              "  '04-02-2022'],\n",
              " ['7934',\n",
              "  'MILLER',\n",
              "  'CLERK',\n",
              "  '7782',\n",
              "  '01-03-1982',\n",
              "  '1300',\n",
              "  'null',\n",
              "  '10',\n",
              "  '05-02-2022'],\n",
              " ['1234', 'SEKHAR', 'doctor', '7777', 'null', '667', '78', '80', '06-02-2022'],\n",
              " ['7369',\n",
              "  'SMITH',\n",
              "  'CLERK',\n",
              "  '7902',\n",
              "  '17-12-1980',\n",
              "  '800',\n",
              "  'null',\n",
              "  '20',\n",
              "  '07-02-2022'],\n",
              " ['7499',\n",
              "  'ALLEN',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '20-02-1981',\n",
              "  '1600',\n",
              "  '300',\n",
              "  '30',\n",
              "  '08-02-2022'],\n",
              " ['7521',\n",
              "  'WARD',\n",
              "  'SALESMAN',\n",
              "  '7698',\n",
              "  '22-02-1981',\n",
              "  '1250',\n",
              "  '500',\n",
              "  '30',\n",
              "  'null'],\n",
              " ['7566',\n",
              "  'JONES',\n",
              "  'MANAGER',\n",
              "  '7839',\n",
              "  '04-02-1981',\n",
              "  '2975',\n",
              "  'null',\n",
              "  '20',\n",
              "  '01-02-2021']]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = r1.collect()[0]\n",
        "skipline = r1.collect()[0]\n",
        "print(columns)\n",
        "print(skipline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSCK-r8zW7ts",
        "outputId": "c8ec3368-c0da-4508-c025-314f25a76179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EMPNO', 'ENAME', 'JOB', 'MGR', 'HIREDATE', 'SAL', 'COMM', 'DEPTNO', 'UPDATED_DATE']\n",
            "['EMPNO', 'ENAME', 'JOB', 'MGR', 'HIREDATE', 'SAL', 'COMM', 'DEPTNO', 'UPDATED_DATE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sk_df = r1.filter(lambda a : a!= skipline).toDF(columns)\n",
        "\n",
        "sk_df.show(10)\n",
        "print(sk_df.count())\n",
        "sk_df.printSchema()\n",
        "print(type(sk_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7TGp5atXPWy",
        "outputId": "7b6e4240-216e-4f77-977d-e40a34bc2b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+----+----------+----+----+------+------------+\n",
            "|EMPNO| ENAME|      JOB| MGR|  HIREDATE| SAL|COMM|DEPTNO|UPDATED_DATE|\n",
            "+-----+------+---------+----+----------+----+----+------+------------+\n",
            "| 7369| SMITH|    CLERK|7902|17-12-1980| 800|null|    20|  01-01-2022|\n",
            "| 7499| ALLEN| SALESMAN|7698|20-02-1981|1600| 300|    30|  02-01-2022|\n",
            "| 7521|  WARD| SALESMAN|7698|22-02-1981|1250| 500|    30|  03-01-2022|\n",
            "| 7566| JONES|  MANAGER|7839|04-02-1981|2975|null|    20|  04-01-2022|\n",
            "| 7654|MARTIN| SALESMAN|7698|21-09-1981|1250|1400|    30|  05-01-2022|\n",
            "| 7698|   SGR|  MANAGER|7839|05-01-1981|2850|null|    30|  06-01-2022|\n",
            "| 7782|  RAVI|  MANAGER|7839|06-09-1981|2450|null|    10|  07-01-2022|\n",
            "| 7788| SCOTT|  ANALYST|7566|19-04-1987|3000|null|    20|  08-01-2022|\n",
            "| 7839|  KING|PRESIDENT|null|      null|5000|null|    10|        null|\n",
            "| 7844|TURNER| SALESMAN|7698|09-08-1981|1500|   0|    30|  01-02-2022|\n",
            "+-----+------+---------+----+----------+----+----+------+------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "19\n",
            "root\n",
            " |-- EMPNO: string (nullable = true)\n",
            " |-- ENAME: string (nullable = true)\n",
            " |-- JOB: string (nullable = true)\n",
            " |-- MGR: string (nullable = true)\n",
            " |-- HIREDATE: string (nullable = true)\n",
            " |-- SAL: string (nullable = true)\n",
            " |-- COMM: string (nullable = true)\n",
            " |-- DEPTNO: string (nullable = true)\n",
            " |-- UPDATED_DATE: string (nullable = true)\n",
            "\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how to get 53 th weak years from last 50 years"
      ],
      "metadata": {
        "id": "YAmzJhkhz2T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "we_df = spark.createDataFrame([(i,\"01/01/\"+str(i)+\"\")for i in range(1990,2050)],['id','year'])\n",
        "\n",
        "we_df = we_df.withColumn('date',to_date('year','dd/mm/yyyy')).withColumn('week',weekofyear('date')).filter('week= 53')\n",
        "we_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_0PX70l3KY8",
        "outputId": "882f4519-1b16-4ebf-f19c-433b1461556c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+----------+----+\n",
            "|  id|      year|      date|week|\n",
            "+----+----------+----------+----+\n",
            "|1993|01/01/1993|1993-01-01|  53|\n",
            "|1999|01/01/1999|1999-01-01|  53|\n",
            "|2005|01/01/2005|2005-01-01|  53|\n",
            "|2010|01/01/2010|2010-01-01|  53|\n",
            "|2016|01/01/2016|2016-01-01|  53|\n",
            "|2021|01/01/2021|2021-01-01|  53|\n",
            "|2027|01/01/2027|2027-01-01|  53|\n",
            "|2033|01/01/2033|2033-01-01|  53|\n",
            "|2038|01/01/2038|2038-01-01|  53|\n",
            "|2044|01/01/2044|2044-01-01|  53|\n",
            "|2049|01/01/2049|2049-01-01|  53|\n",
            "+----+----------+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a dataframe"
      ],
      "metadata": {
        "id": "Kagev9gFLmde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cr_df = spark.createDataFrame([(i,\"02/01/\"+str(i)+\"\") for i in range (1999,2050)],['id','year'])\n",
        "\n",
        "cr_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWtj-2i3L1Ef",
        "outputId": "3f45f2bf-ae55-40a6-a70e-3ed242ef159b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+\n",
            "|  id|      year|\n",
            "+----+----------+\n",
            "|1999|02/01/1999|\n",
            "|2000|02/01/2000|\n",
            "|2001|02/01/2001|\n",
            "|2002|02/01/2002|\n",
            "|2003|02/01/2003|\n",
            "|2004|02/01/2004|\n",
            "|2005|02/01/2005|\n",
            "|2006|02/01/2006|\n",
            "|2007|02/01/2007|\n",
            "|2008|02/01/2008|\n",
            "|2009|02/01/2009|\n",
            "|2010|02/01/2010|\n",
            "|2011|02/01/2011|\n",
            "|2012|02/01/2012|\n",
            "|2013|02/01/2013|\n",
            "|2014|02/01/2014|\n",
            "|2015|02/01/2015|\n",
            "|2016|02/01/2016|\n",
            "|2017|02/01/2017|\n",
            "|2018|02/01/2018|\n",
            "+----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how to handle or how to read variable/dynamic no.of columns data file ( with Out Header File)?"
      ],
      "metadata": {
        "id": "uJDO9Mk1HT_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format('text').load('/content/emp_without_header.txt').withColumn('New',split('value',','))\n",
        "\n",
        "# To find max No.of coulumns in a table\n",
        "col_size = df.select(max(size(col('New'))))\n",
        "\n",
        "df.show(5,truncate=True)\n",
        "col_size.show()\n",
        "print(type(df))\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpSgTg4kHTdi",
        "outputId": "8e1c210a-4ecc-4d6f-8603-6250ebcabb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|               value|                 New|\n",
            "+--------------------+--------------------+\n",
            "|7369,SMITH,CLERK,...|[7369, SMITH, CLE...|\n",
            "|7499,ALLEN,SALESM...|[7499, ALLEN, SAL...|\n",
            "|7521,WARD,SALESMA...|[7521, WARD, SALE...|\n",
            "|7566,JONES,MANAGE...|[7566, JONES, MAN...|\n",
            "|7654,MARTIN,SALES...|[7654, MARTIN, SA...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------+\n",
            "|max(size(New))|\n",
            "+--------------+\n",
            "|             9|\n",
            "+--------------+\n",
            "\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "root\n",
            " |-- value: string (nullable = true)\n",
            " |-- New: array (nullable = true)\n",
            " |    |-- element: string (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(col_size.collect()[0][0]):\n",
        "  df = df.withColumn('col'+str(i),df['New'][i])\n",
        "df.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss_Vt-XjHaUA",
        "outputId": "ce83ed70-23e0-423b-f85c-69142e561f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------+----------------------------------------------------------------------+----+------+---------+----+----------+----+----+----+----------+\n",
            "|value                                                       |New                                                                   |col0|col1  |col2     |col3|col4      |col5|col6|col7|col8      |\n",
            "+------------------------------------------------------------+----------------------------------------------------------------------+----+------+---------+----+----------+----+----+----+----------+\n",
            "|7369,SMITH,CLERK,7902,17-12-1980,800,null,20,01-01-2022     |[7369, SMITH, CLERK, 7902, 17-12-1980, 800, null, 20, 01-01-2022]     |7369|SMITH |CLERK    |7902|17-12-1980|800 |null|20  |01-01-2022|\n",
            "|7499,ALLEN,SALESMAN,7698,20-02-1981,1600,300,30,02-01-2022  |[7499, ALLEN, SALESMAN, 7698, 20-02-1981, 1600, 300, 30, 02-01-2022]  |7499|ALLEN |SALESMAN |7698|20-02-1981|1600|300 |30  |02-01-2022|\n",
            "|7521,WARD,SALESMAN,7698,22-02-1981,1250,500,30,03-01-2022   |[7521, WARD, SALESMAN, 7698, 22-02-1981, 1250, 500, 30, 03-01-2022]   |7521|WARD  |SALESMAN |7698|22-02-1981|1250|500 |30  |03-01-2022|\n",
            "|7566,JONES,MANAGER,7839,04-02-1981,2975,null,20,04-01-2022  |[7566, JONES, MANAGER, 7839, 04-02-1981, 2975, null, 20, 04-01-2022]  |7566|JONES |MANAGER  |7839|04-02-1981|2975|null|20  |04-01-2022|\n",
            "|7654,MARTIN,SALESMAN,7698,21-09-1981,1250,1400,30,05-01-2022|[7654, MARTIN, SALESMAN, 7698, 21-09-1981, 1250, 1400, 30, 05-01-2022]|7654|MARTIN|SALESMAN |7698|21-09-1981|1250|1400|30  |05-01-2022|\n",
            "|7698,SGR,MANAGER,7839,05-01-1981,2850,null,30,06-01-2022    |[7698, SGR, MANAGER, 7839, 05-01-1981, 2850, null, 30, 06-01-2022]    |7698|SGR   |MANAGER  |7839|05-01-1981|2850|null|30  |06-01-2022|\n",
            "|7782,RAVI,MANAGER,7839,06-09-1981,2450,null,10,07-01-2022   |[7782, RAVI, MANAGER, 7839, 06-09-1981, 2450, null, 10, 07-01-2022]   |7782|RAVI  |MANAGER  |7839|06-09-1981|2450|null|10  |07-01-2022|\n",
            "|7788,SCOTT,ANALYST,7566,19-04-1987,3000,null,20,08-01-2022  |[7788, SCOTT, ANALYST, 7566, 19-04-1987, 3000, null, 20, 08-01-2022]  |7788|SCOTT |ANALYST  |7566|19-04-1987|3000|null|20  |08-01-2022|\n",
            "|7839,KING,PRESIDENT,null,null,5000,null,10,null             |[7839, KING, PRESIDENT, null, null, 5000, null, 10, null]             |7839|KING  |PRESIDENT|null|null      |5000|null|10  |null      |\n",
            "|7844,TURNER,SALESMAN,7698,09-08-1981,1500,0,30,01-02-2022   |[7844, TURNER, SALESMAN, 7698, 09-08-1981, 1500, 0, 30, 01-02-2022]   |7844|TURNER|SALESMAN |7698|09-08-1981|1500|0   |30  |01-02-2022|\n",
            "|7876,ADAMS,CLERK,7788,23-05-1987,1100,null,20,02-02-2022    |[7876, ADAMS, CLERK, 7788, 23-05-1987, 1100, null, 20, 02-02-2022]    |7876|ADAMS |CLERK    |7788|23-05-1987|1100|null|20  |02-02-2022|\n",
            "|7900,JAMES,CLERK,7698,12-03-1981,950,null,30,03-02-2022     |[7900, JAMES, CLERK, 7698, 12-03-1981, 950, null, 30, 03-02-2022]     |7900|JAMES |CLERK    |7698|12-03-1981|950 |null|30  |03-02-2022|\n",
            "|7902,FORD,ANALYST,7566,12-03-1981,3000,null,20,04-02-2022   |[7902, FORD, ANALYST, 7566, 12-03-1981, 3000, null, 20, 04-02-2022]   |7902|FORD  |ANALYST  |7566|12-03-1981|3000|null|20  |04-02-2022|\n",
            "|7934,MILLER,CLERK,7782,01-03-1982,1300,null,10,05-02-2022   |[7934, MILLER, CLERK, 7782, 01-03-1982, 1300, null, 10, 05-02-2022]   |7934|MILLER|CLERK    |7782|01-03-1982|1300|null|10  |05-02-2022|\n",
            "|1234,SEKHAR,doctor,7777,null,667,78,80,06-02-2022           |[1234, SEKHAR, doctor, 7777, null, 667, 78, 80, 06-02-2022]           |1234|SEKHAR|doctor   |7777|null      |667 |78  |80  |06-02-2022|\n",
            "|7369,SMITH,CLERK,7902,17-12-1980,800,null,20,07-02-2022     |[7369, SMITH, CLERK, 7902, 17-12-1980, 800, null, 20, 07-02-2022]     |7369|SMITH |CLERK    |7902|17-12-1980|800 |null|20  |07-02-2022|\n",
            "|7499,ALLEN,SALESMAN,7698,20-02-1981,1600,300,30,08-02-2022  |[7499, ALLEN, SALESMAN, 7698, 20-02-1981, 1600, 300, 30, 08-02-2022]  |7499|ALLEN |SALESMAN |7698|20-02-1981|1600|300 |30  |08-02-2022|\n",
            "|7521,WARD,SALESMAN,7698,22-02-1981,1250,500,30,null         |[7521, WARD, SALESMAN, 7698, 22-02-1981, 1250, 500, 30, null]         |7521|WARD  |SALESMAN |7698|22-02-1981|1250|500 |30  |null      |\n",
            "|7566,JONES,MANAGER,7839,04-02-1981,2975,null,20,01-02-2021  |[7566, JONES, MANAGER, 7839, 04-02-1981, 2975, null, 20, 01-02-2021]  |7566|JONES |MANAGER  |7839|04-02-1981|2975|null|20  |01-02-2021|\n",
            "+------------------------------------------------------------+----------------------------------------------------------------------+----+------+---------+----+----------+----+----+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop('value').drop('New')\n",
        "df1.show(truncate = False)\n",
        "df1.printSchema()\n",
        "print(type(df1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8iZu-TDHeho",
        "outputId": "4c5cd868-bc71-4da3-9e14-1cf388a3b968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+---------+----+----------+----+----+----+----------+\n",
            "|col0|col1  |col2     |col3|col4      |col5|col6|col7|col8      |\n",
            "+----+------+---------+----+----------+----+----+----+----------+\n",
            "|7369|SMITH |CLERK    |7902|17-12-1980|800 |null|20  |01-01-2022|\n",
            "|7499|ALLEN |SALESMAN |7698|20-02-1981|1600|300 |30  |02-01-2022|\n",
            "|7521|WARD  |SALESMAN |7698|22-02-1981|1250|500 |30  |03-01-2022|\n",
            "|7566|JONES |MANAGER  |7839|04-02-1981|2975|null|20  |04-01-2022|\n",
            "|7654|MARTIN|SALESMAN |7698|21-09-1981|1250|1400|30  |05-01-2022|\n",
            "|7698|SGR   |MANAGER  |7839|05-01-1981|2850|null|30  |06-01-2022|\n",
            "|7782|RAVI  |MANAGER  |7839|06-09-1981|2450|null|10  |07-01-2022|\n",
            "|7788|SCOTT |ANALYST  |7566|19-04-1987|3000|null|20  |08-01-2022|\n",
            "|7839|KING  |PRESIDENT|null|null      |5000|null|10  |null      |\n",
            "|7844|TURNER|SALESMAN |7698|09-08-1981|1500|0   |30  |01-02-2022|\n",
            "|7876|ADAMS |CLERK    |7788|23-05-1987|1100|null|20  |02-02-2022|\n",
            "|7900|JAMES |CLERK    |7698|12-03-1981|950 |null|30  |03-02-2022|\n",
            "|7902|FORD  |ANALYST  |7566|12-03-1981|3000|null|20  |04-02-2022|\n",
            "|7934|MILLER|CLERK    |7782|01-03-1982|1300|null|10  |05-02-2022|\n",
            "|1234|SEKHAR|doctor   |7777|null      |667 |78  |80  |06-02-2022|\n",
            "|7369|SMITH |CLERK    |7902|17-12-1980|800 |null|20  |07-02-2022|\n",
            "|7499|ALLEN |SALESMAN |7698|20-02-1981|1600|300 |30  |08-02-2022|\n",
            "|7521|WARD  |SALESMAN |7698|22-02-1981|1250|500 |30  |null      |\n",
            "|7566|JONES |MANAGER  |7839|04-02-1981|2975|null|20  |01-02-2021|\n",
            "+----+------+---------+----+----------+----+----+----+----------+\n",
            "\n",
            "root\n",
            " |-- col0: string (nullable = true)\n",
            " |-- col1: string (nullable = true)\n",
            " |-- col2: string (nullable = true)\n",
            " |-- col3: string (nullable = true)\n",
            " |-- col4: string (nullable = true)\n",
            " |-- col5: string (nullable = true)\n",
            " |-- col6: string (nullable = true)\n",
            " |-- col7: string (nullable = true)\n",
            " |-- col8: string (nullable = true)\n",
            "\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# udf register"
      ],
      "metadata": {
        "id": "qjm5YnWn1E5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# UDF\n",
        "\n",
        "def f1(x):\n",
        "  return ((x*x)-x)\n",
        "\n",
        "spark.udf.register('fun',f1,IntegerType())\n",
        "fun = udf(f1,IntegerType())\n",
        "\n",
        "print(f1(5))"
      ],
      "metadata": {
        "id": "g9S32Vmp1IE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5.select('ENAME',sqrt('SAL'),fun('SAL')).show()"
      ],
      "metadata": {
        "id": "oNpO3BOY1KJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how to handle bad data\n",
        "\n",
        "Spark read Mode:\n",
        "\n",
        "1.PERMISSIVE - allows bad data - it's spark default mode\n",
        "\n",
        "2.FAILFAST - won't allows bad data -it raise expection - it won't process further\n",
        "\n",
        "3.DROPMALFORMED - drops bad records based on schema -it won't save bad records\n",
        "\n",
        "4.badrecordsPath - save good data in table and saves bad it another path"
      ],
      "metadata": {
        "id": "Q3Pdmj4p1Zyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad = spark.read.format('csv').option('header',True).option('inferSchema',True).option('nullValue','null').load('/content/channels.csv')\n",
        "\n",
        "bad.show()\n",
        "\n",
        "bad.schema"
      ],
      "metadata": {
        "id": "3QCJjO1v1cXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# need to add _corrupt_record column string type in custom made schema\n",
        "schema  = StructType([StructField('CHANNEL_ID', IntegerType(), True),\n",
        "                      StructField('CHANNEL_DESC', StringType(), True),\n",
        "                      StructField('CHANNEL_CLASS', StringType(), True),\n",
        "                      StructField('CHANNEL_CLASS_ID', IntegerType(), True),\n",
        "                      StructField('CHANNEL_TOTAL', StringType(), True),\n",
        "                      StructField('CHANNEL_TOTAL_ID', IntegerType(), True),\n",
        "                      StructField(\"BadData\", StringType(), True)])"
      ],
      "metadata": {
        "id": "BIvx_0Ed1phT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save bad Records Using mode - PERMISSIVE and _corrupt_record ,columnNameofCorrputRecord\n",
        "\n",
        "bad1 = spark.read.format('csv').schema(schema).option('Mode','PERMISSIVE').option('ColumnNameOfCorruptRecord','BadData').option('header',True).option('nullValue','null').load('/content/channels.csv')\n",
        "bad1.show()\n",
        "\n",
        "# filter good records\n",
        "goodData = bad1.filter('BadData is Null').drop('BAdData')\n",
        "goodData.show()\n",
        "\n",
        "# filter corrupt records\n",
        "bad3 = bad1.filter('BadData is Not Null')\n",
        "bad3.show()"
      ],
      "metadata": {
        "id": "P6c993rM1sGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mode - FAILFAST\n",
        "\n",
        "bad = spark.read.format('csv').schema(schema).option('mode','FAILFAST').option('header',True).option('nullValue','null').load('/content/channels.csv')\n",
        "bad.show()"
      ],
      "metadata": {
        "id": "RMxTTYZ91vB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DROPMALFORMED\n",
        "\n",
        "bad = spark.read.format('csv').schema(schema).option('mode','DROPMALFORMED').option('header',True).option('nullValue','null').load('/content/channels.csv')\n",
        "bad.show()"
      ],
      "metadata": {
        "id": "dqFplain1xYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Data Frame from REST API"
      ],
      "metadata": {
        "id": "nJxbbzLg182I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#REST API -Accessing the data over internet through Urls\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "api = requests.request('GET','https://api.github.com/users/hadley/orgs')\n",
        "\n",
        "data = api.json()\n",
        "\n",
        "file = open('/content/sample_data/apidata.json','a')\n",
        "\n",
        "for record in data:\n",
        "  file.write(\"%s\\n\" %record)\n",
        "\n",
        "api_df = spark.read.format('json').load('/content/sample_data/apidata.json')"
      ],
      "metadata": {
        "id": "GG_H0EOj2BSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(api.json()))\n",
        "print(len(api.json()))"
      ],
      "metadata": {
        "id": "vyk4lnR_2C7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_df.show(10)\n",
        "api_df.printSchema()\n",
        "api_df.count()"
      ],
      "metadata": {
        "id": "rLEtCkNh2EZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}